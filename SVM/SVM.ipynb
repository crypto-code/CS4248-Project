{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVM",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LV8WmZRHg8cZ",
        "outputId": "74145f38-85ce-4347-fa2f-6f8baf6d1167"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.chunk import RegexpParser\n",
        "from random import shuffle\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from nltk.util import ngrams\n",
        "from sklearn.metrics import precision_recall_fscore_support as score\n",
        "from nltk.util import everygrams"
      ],
      "metadata": {
        "id": "yBNaRFuHtwb7"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNamrdfE6GmH",
        "outputId": "6b2fcc84-4ad4-4044-ec35-c9642358e2a0"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.classify.scikitlearn import SklearnClassifier\n",
        "from nltk.metrics.scores import accuracy, precision, recall, f_measure\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC,LinearSVC\n",
        "import collections\n",
        "import os\n",
        "import re\n",
        "import json"
      ],
      "metadata": {
        "id": "7XMtiuTa3Tz_"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = \"../json_data_train.json\"\n",
        "test_path = \"../json_data_test.json\"\n",
        "glove_embedding_path = './glove.6B.300d.txt'"
      ],
      "metadata": {
        "id": "JwG0bnj1nuWR"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_json_file(path):\n",
        "    # Opening JSON file\n",
        "    f = open(path)\n",
        "    # returns JSON object as\n",
        "    # a dictionary\n",
        "    data = json.load(f)\n",
        "    text_value = dict()\n",
        "    for key in data:\n",
        "      val = data.get(key)\n",
        "      text = val['text']\n",
        "      value = val['keywords']\n",
        "      text_value[text] = value\n",
        "    return text_value\n"
      ],
      "metadata": {
        "id": "3nbAptRCttjI"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_candidate_phrases(file):\n",
        "    #Tokenize\n",
        "    tokens = word_tokenize(file)\n",
        "    # Chunking\n",
        "    tagged = nltk.pos_tag(tokens)\n",
        "    chunkGram = r\"\"\" PHRASE: \n",
        "                        {(<JJ>*  <NN.*>* )* <NN.*>*}\n",
        "                \"\"\"\n",
        "    chunkParser = RegexpParser(chunkGram)\n",
        "    chunked = chunkParser.parse(tagged)\n",
        "\n",
        "    candidate_keywords = []\n",
        "    for tree in chunked.subtrees():\n",
        "        if tree.label() == 'PHRASE':\n",
        "            candidate_keyword = ' '.join([x for x,y in tree.leaves()])\n",
        "            candidate_keywords.append(candidate_keyword)\n",
        "    candidate_keywords = [w for w in candidate_keywords if len(w) > 3 and len(w.split(' ')) < 10 and w.isalpha() ] \n",
        "    return candidate_keywords"
      ],
      "metadata": {
        "id": "SzjP7lqM3fgK"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_index = {}\n",
        "f = open(glove_embedding_path, encoding=\"utf8\")\n",
        "for line in tqdm(f):\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    try:\n",
        "       coefs = np.asarray(values[1:], dtype='float32')\n",
        "       embeddings_index[word] = coefs\n",
        "    except ValueError:\n",
        "       pass\n",
        "f.close()\n",
        "print('Found %s word vectors.' % len(embeddings_index))\n"
      ],
      "metadata": {
        "id": "GfZIta8rn2e8",
        "outputId": "55885914-21a6-4c0c-970c-18273d41556c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "400000it [00:29, 13783.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_phrase_vec(phrase):\n",
        "  M = []\n",
        "  for w in phrase:\n",
        "    try:\n",
        "      M.append(embeddings_index[w])\n",
        "    except:\n",
        "      continue\n",
        "  M = np.array(M)\n",
        "  v = M.sum(axis=0)\n",
        "  if type(v) != np.ndarray:\n",
        "    return np.zeros(300)\n",
        "  return  v / np.sqrt((v ** 2).sum())"
      ],
      "metadata": {
        "id": "0r8NbiUHn7RM"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_features(doc,phrase,candidate_list):\n",
        "  features = {}\n",
        "  features['length'] = len(phrase.split(' '))\n",
        "  features['part_of_speech'] = ' '.join([pos for word,pos in nltk.pos_tag(nltk.word_tokenize(phrase))])\n",
        "  phrase_list = create_phrase_vec(phrase)\n",
        "  if len(phrase_list):\n",
        "    for i in range(0,len(phrase_list)):\n",
        "      features['vector' + str(i)] = phrase_list[i]\n",
        "  position_list = [ m.start()/float(len(doc)) for m in re.finditer(re.escape(phrase),doc,flags=re.IGNORECASE)] \n",
        "  if len(position_list):\n",
        "      for i in range(0,len(position_list)):\n",
        "          features['occurrance' + str(i)] = position_list[i]\n",
        "  features['frequency'] = len(position_list)/ float(len(set(candidate_list)))\n",
        "  return features"
      ],
      "metadata": {
        "id": "NmF80nzP3kjZ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_feature_list(train_path, class_mapping):\n",
        "  feature_list = []\n",
        "  features = read_json_file(train_path)\n",
        "  candidate_list = []\n",
        "  for text, value in tqdm(features.items()):\n",
        "    candidates = get_candidate_phrases(text)\n",
        "    candidate_list += candidates\n",
        "    keywords =  list(value.keys())\n",
        "    classes = list(value.values())\n",
        "    for cd in candidates:\n",
        "      feature = create_features(text,cd,candidates)\n",
        "      if cd in keywords:\n",
        "        tag = value.get(cd)[0][2]\n",
        "        label = class_mapping[tag]\n",
        "      else:\n",
        "        label = class_mapping['Normal']\n",
        "      feature_list.append([feature,label])    \n",
        "  return  feature_list"
      ],
      "metadata": {
        "id": "m8uCvAYnFmwg"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_mapping = {\n",
        " 'Normal': 0,\n",
        " 'Task' : 1,\n",
        " 'Process' : 2,\n",
        " 'Material': 3\n",
        "}"
      ],
      "metadata": {
        "id": "cAA4l5etNp-w"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_list = create_feature_list(train_path, class_mapping)\n",
        "print(\" \")\n",
        "print('Length of feature list',len(feature_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoQ8UM9tPIDy",
        "outputId": "a131c67d-4b82-4264-e90d-fbe4b9cf0fbd"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 350/350 [00:09<00:00, 37.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "Length of feature list 6265\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('number of keywords', len([x for x,y in feature_list if y != 0]))\n",
        "print('number of Task keywords', len([x for x,y in feature_list if y == 1]))\n",
        "print('number of Process keywords', len([x for x,y in feature_list if y == 2]))\n",
        "print('number of Material keywords', len([x for x,y in feature_list if y == 3]))\n",
        "print('number of non keywords', len([x for x,y in feature_list if y == 0]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voKf65BKGYG5",
        "outputId": "c6c90608-b2d7-435a-ef15-873a66cc1553"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of keywords 857\n",
            "number of Task keywords 41\n",
            "number of Process keywords 278\n",
            "number of Material keywords 538\n",
            "number of non keywords 5408\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shuffle(feature_list)\n",
        "non_candidates_list_train = [(x,y) for x,y in feature_list if y == 0][:500]\n",
        "task_list_train = [(x,y) for x,y in feature_list if y == 1][:41]\n",
        "process_list_train = [(x,y) for x,y in feature_list if y == 2][:278]\n",
        "material_list_train = [(x,y) for x,y in feature_list if y == 3][:500]\n",
        "shuffle(non_candidates_list_train)\n",
        "shuffle(task_list_train)\n",
        "shuffle(process_list_train)\n",
        "shuffle(material_list_train)\n",
        "training_set = []\n",
        "training_set.extend(non_candidates_list_train)\n",
        "training_set.extend(task_list_train)\n",
        "training_set.extend(process_list_train)\n",
        "training_set.extend(material_list_train)"
      ],
      "metadata": {
        "id": "6SZllCFEzvGL"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_list = np.array(feature_list)\n",
        "X = feature_list[:,0]\n",
        "Y = feature_list[:,1]"
      ],
      "metadata": {
        "id": "DrXGjyVDRNQA"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y)"
      ],
      "metadata": {
        "id": "zPgzctkAQ3nE"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array(X_train).reshape(-1,1)\n",
        "y_train = np.array(y_train).reshape(-1,1)\n",
        "feature_list_train = np.concatenate((X_train,y_train),axis=1)\n",
        "print('Train size',feature_list_train.shape)\n",
        "\n",
        "X_test = np.array(X_test).reshape(-1,1)\n",
        "y_test = np.array(y_test).reshape(-1,1)\n",
        "feature_list_test = np.concatenate((X_test,y_test),axis=1)\n",
        "print('Test size',feature_list_test.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "casGKsU9eJmP",
        "outputId": "a3d51092-8efd-410b-b989-052581f81d3f"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size (5012, 2)\n",
            "Test size (1253, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation_metric(y_test,y_pred):\n",
        "  precision, recall, fscore, support = score(y_test, y_pred,average=None,labels=[0,1,2,3])\n",
        "  print('Class Non Keyword: ')\n",
        "  print('Precision: ',precision[0])\n",
        "  print('Recall: ',recall[0])\n",
        "  print('Fscore: ',fscore[0])\n",
        "  print('support: ',support[0])\n",
        "  print(' ')\n",
        "  print('Class Task: ')\n",
        "  print('Precision: ',precision[1])\n",
        "  print('Recall: ',recall[1])\n",
        "  print('Fscore: ',fscore[1])\n",
        "  print('support: ',support[1])\n",
        "  print(' ')\n",
        "  print('Class Process: ')\n",
        "  print('Precision: ',precision[2])\n",
        "  print('Recall: ',recall[2])\n",
        "  print('Fscore: ',fscore[2])\n",
        "  print('support: ',support[2])\n",
        "  print(' ')\n",
        "  print('Class Material: ')\n",
        "  print('Precision: ',precision[3])\n",
        "  print('Recall: ',recall[3])\n",
        "  print('Fscore: ',fscore[3])\n",
        "  print('support: ',support[3])\n",
        "  print(' ')\n",
        "  print(\"Overall:\")\n",
        "  print(\"Micro averaged F score\",f1_score(y_test, y_pred, average='micro'))\n",
        "  print(\"Macro averaged F score\",f1_score(y_test, y_pred, average='macro'))"
      ],
      "metadata": {
        "id": "nv0rJV-M8o3i"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier =  SklearnClassifier(LinearSVC(max_iter=5000)).train(training_set)\n",
        "y_pred = classifier.classify_many(feature_list_test[:,0])\n",
        "y_test = feature_list_test[:,1].tolist()\n",
        "print (\"Accuracy : \",nltk.classify.accuracy(classifier,feature_list_test) * 100)\n",
        "print(' ')\n",
        "evaluation_metric(y_test, y_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0WfRmBwUeKY",
        "outputId": "7b69eb34-1b6b-4b04-dfa4-13c7e6775990"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy :  64.96408619313647\n",
            " \n",
            "Class Non Keyword: \n",
            "Precision:  0.9290240811153359\n",
            "Recall:  0.677449168207024\n",
            "Fscore:  0.7835382148583645\n",
            "support:  1082\n",
            " \n",
            "Class Task: \n",
            "Precision:  0.0\n",
            "Recall:  0.0\n",
            "Fscore:  0.0\n",
            "support:  8\n",
            " \n",
            "Class Process: \n",
            "Precision:  0.13\n",
            "Recall:  0.23636363636363636\n",
            "Fscore:  0.16774193548387098\n",
            "support:  55\n",
            " \n",
            "Class Material: \n",
            "Precision:  0.18681318681318682\n",
            "Recall:  0.6296296296296297\n",
            "Fscore:  0.288135593220339\n",
            "support:  108\n",
            " \n",
            "Overall:\n",
            "Micro averaged F score 0.6496408619313647\n",
            "Macro averaged F score 0.3098539358906436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_test_feature_list(test_path, class_mapping):\n",
        "  feature_list = []\n",
        "  features = read_json_file(train_path)\n",
        "  for text, value in tqdm(features.items()):\n",
        "    candidates = get_candidate_phrases(text)\n",
        "    keywords =  list(value.keys())\n",
        "    classes = list(value.values())\n",
        "    print(classes)\n",
        "\n",
        "    for i,kw in enumerate(keywords):\n",
        "      feature = create_features(text,kw,candidates)\n",
        "      label = class_mapping[classes[i][0][2]]\n",
        "      feature_list.append([feature,label])\n",
        "      for cd in candidates:\n",
        "        if cd not in keywords:\n",
        "          feature = create_features(text,cd,candidates)\n",
        "          label = class_mapping['Normal']\n",
        "          feature_list.append([feature,label])    \n",
        "  return feature_list "
      ],
      "metadata": {
        "id": "V62f3jnOcWrl"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_feature_list = create_feature_list(test_path,class_mapping)\n",
        "test_feature_list = np.asarray(test_feature_list)\n",
        "print(\" \")\n",
        "print('Length of test feature list',len(test_feature_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orhnaxjKpARH",
        "outputId": "704cfbd5-49f7-4251-ddf0-542e5608e5ac"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:03<00:00, 33.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "Length of test feature list 2135\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy : \",nltk.classify.accuracy(classifier,test_feature_list) * 100)\n",
        "print(' ')\n",
        "y_pred = classifier.classify_many(test_feature_list[:,0])\n",
        "y_test = test_feature_list[:,1].tolist()\n",
        "evaluation_metric(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6h3SBbbnp3N4",
        "outputId": "47627b34-b351-48a2-f5e2-49d3571fc0e4"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy :  63.559718969555036\n",
            " \n",
            "Class Non Keyword: \n",
            "Precision:  0.9132385938668661\n",
            "Recall:  0.674585635359116\n",
            "Fscore:  0.7759771210676835\n",
            "support:  1810\n",
            " \n",
            "Class Task: \n",
            "Precision:  0.0\n",
            "Recall:  0.0\n",
            "Fscore:  0.0\n",
            "support:  19\n",
            " \n",
            "Class Process: \n",
            "Precision:  0.14906832298136646\n",
            "Recall:  0.22857142857142856\n",
            "Fscore:  0.18045112781954886\n",
            "support:  105\n",
            " \n",
            "Class Material: \n",
            "Precision:  0.17582417582417584\n",
            "Recall:  0.5572139303482587\n",
            "Fscore:  0.26730310262529833\n",
            "support:  201\n",
            " \n",
            "Overall:\n",
            "Micro averaged F score 0.6355971896955503\n",
            "Macro averaged F score 0.30593283787813264\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}